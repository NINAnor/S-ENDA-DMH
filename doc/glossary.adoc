[[glossary]]
== Glossary of Terms and Names 

//links to tables and other sections not updated

[%header, cols=2*]
|===
|Term
|Description

|[[application-service]]Application service
|TBC

|[[CMD-dataset]]CDM dataset
|A dataset that “may be a NetCDF, HDF5, GRIB, etc. file, an OPeNDAP dataset, a collection of files, or anything else which can be accessed through the NetCDF API.” https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/CDM/[Unidata Common Data Model] 

|[[configuration-metadata]]Configuration metadata
|See Configuration metadata definition in Table 2

|[[controlled-vocabulary]]Controlled vocabulary
|A carefully selected list of terms (words and phrases) controlled by some authority. They are used to tag information elements (such as datasets) so that they are easier to search for. (see https://en.wikipedia.org/wiki/Controlled_vocabulary[Wikipedia article]) A basic element in the implementation of the <<semantic-web,Semantic web>>.

|[[data-life-cycle-management]]Data life cycle management
|“Data life cycle management (DLM) is a policy-based approach to managing the flow of an information system's data throughout its life cycle: from creation and initial storage to the time when it becomes obsolete and is deleted.” Excerpt from TechTarget article.
Alias: life cycle management

|[[data-management-plan]]Data Management Plan
|“A data management plan (DMP) is a written document that describes the data you expect to acquire or generate during the course of a research project, how you will manage, describe, analyse, and store those data, and what mechanisms you will use at the end of your project to share and preserve your data.” Stanford Libraries

|[[data-centre]]Data centre
|A combination of a (distributed) data repository and the data availability services and information about them (e.g., a metadata catalog). A data centre may include contributions from several other data centres.  

|[[data-management]]Data management
|How data sets are handled by the organisation through the entire value chain - include receiving, storing, metadata management and data retrieval.

|[[data-provenance]]Data provenance
|“The term ‘data provenance’ refers to a record trail that accounts for the origin of a piece of data (in a database, document or repository) together with an explanation of how and why it got to the present place.” (Gupta, 2009). See also Boohers (2015)

|[[data-repository]]Data repository
|A set of distributed components that will hold the data and ensure they can be queried and accessed according to agreed protocols. This component is also known as a Data Node.

|[[dataset]]Dataset
|A dataset is a pre-defined grouping or collection of related data for an intended use. Datasets may be categorised by:

* source, such as observations (in situ, remotely sensed) and numerical model projections and analyses;
* processing level, such as “raw data” (values measured by an instrument), calibrated data, quality-controlled data, derived parameters (preferably with error estimates), temporally and/or spatially aggregated variables;
* data type, including point data, sections and profiles, lines and polylines, polygons, gridded data, volume data, and time series (of  points, grids, etc.).

Data having all of the same characteristics in each category, but different independent variable ranges and/or responding to a specific need, are normally considered part of a single dataset.
In the context of data preservation a dataset consists of the data records and their associated knowledge (information, tools).
In practice, our datasets should conform to the Unidata CDM dataset definition, as much as possible.

|[[discovery-metadata]]Discovery metadata
|See Discovery metadata definition in Table 2

|[[dynamic-geodata]]Dynamic geodata
|Data describing geophysical processes which are continuously evolving over time. Typically these data are used for monitoring and prediction of the weather, sea, climate and environment. 

|[[fari-principles]]FAIR principles
|The four foundational principles of good data management and stewardship: Findability, Accessibility, Interoperability and Reusability. Nature article [RD3], FAIR Data Principles, FAIR metrics proposal, EU H2020 Guidelines

|[[feature-type]]Feature type
|A categorisation of data according to how they are stored, for example, grid, time series, profile, etc. It has been formalised in the NetCDF/CF feature type table, which currently defines eight feature types. 

|[[geodataloven]]Geodataloven
|“Norwegian regulation toward good and efficient access to public geographic information for public and private purposes.” See Deling av geodata – Geodataloven,

|[[geonorge]]Geonorge
|“Geonorge is the national website for map data and other location information in Norway. Users of map data can search for any such information available and access it here.” See Geonorge. 

|[[geographic-information-system]]Geographic Information System
|A geographic information system (GIS) is a system designed to capture, store, manipulate, analyze, manage and present spatial or geographic data. (Clarke, K. C., 1986)
GIS systems have lately evolved in distributed Spatial Data Infrastructures (SDI)

|[[glossary]]Glossary
|Terms and their definitions, possibly with synonyms.

|[[interoperability]]Interoperability
|The ability of data or tools from non-cooperating resources to integrate or work together with minimal effort.

|[linked-data]]Linked data
|A method of publishing structured data so that they can be interlinked and become more useful through semantic queries, i.e., through machine-machine interactions. (see Wikipedia article)

|[[ontology]]Ontology
|A set of concepts with attributes and relationships that define a domain of knowledge. 

|[[opensearch]]OpenSearch
|A collection of simple formats for the sharing of search results (OpenSearch)

|[[product]]Product
|“Product” is not a uniquely defined term among the various providers of dynamical geodata, either nationally or internationally. It is often used synonymously with “dataset.” For the sake of clarity, “product” is not used in this handbook. The term “dataset” is adequate for our purpose. 

|[[semantic-web]]Semantic web
|“The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries". W3C (see Wikipedia article)

|[[site-metadata]]Site metadata
|See Site metadata definition in Table 2

|[[spatial-data-infrastructure]]Spatial Data Infrastructure
|“Spatial Data Infrastructure (SDI) is defined as a framework of policies, institutional arrangements. technologies, data, and people that enables the sharing and effective usage of geographic information by standardising formats and protocols for access and interoperability.” (Tonchovska et al, 2012)
SDI has evolved from GIS.
Among the largest implementations are: NSDI in the USA, INSPIRE in Europe and UNSDI as an effort by the United Nations.
For areas in the Arctic, there is arctic-sdi.org.

|[unified-data-management]]Unified data management
|A common approach to data management in a grouping of separate data management enterprises.

|[[use-metadata]]Use metadata
|See Use metadata definition in Table 2

|[[webportal]]Web portal
|A central website where all users can search, browse, access, transform, display and download datasets irrespective of the data repository in which the data are held.

|[[webservice]]Web service
|Web services are used to communicate metadata, data and to offer processing services. Much effort has been put on standardisation of web services to ensure they are reusable in different contexts. In contrast to web applications, web services communicate with other programs, instead of interactively with users. (See TechTerms article)

|[[workflow-management]]Workflow management
|Workflow management is the process of tracking data, software and other actions on data into a new form of the data. It is related to data provenance, but is usually used in the context of workflow management systems.

|[[scientific-workflow-management-system]](Scientific) Workflow management systems
|A scientific workflow system is a specialised form of a workflow management system designed specifically to compose and execute a series of computational or data manipulation steps, or workflow, in a scientific application. (Wikipedia) As of today, many different frameworks exist with their own proprietary languages, these might eventually get connected by using a common workflow definition language.
|===
